export const projectsAndResearchData = [
  {
    emoji: "ğŸ§‘â€ğŸ«",
    title: "Learnadoodle",
    location: "Washington, DC",
    dates: "April-May 2025",
    short: "Co-founder, CTO, Developer.",
    long: "Designed and built an app to relieve the real burdens of homeschooling - planning, grading, reporting. Releasing in June on Google Play and App Store."
  },
  {
    emoji: "ğŸ“",
    title: "\"Unprecedented Transnational Growth and Rampant Capitalism within the Religious Economy\"",
    location: "Columbia, South Carolina",
    dates: "Feb 2023",
    short: "Written before AI.",
    long: "Abstract: This essay analyzes how the bait-and-switch organization centered around a fear-inducing-evil-galactic-overlord, Xenu, his spacecraft, and exploding volcanoes manages to overcome dozens of external imperatives including litigations for extortion, coercion, tax evasion, and falsification of records..."
  },
  {
    emoji: "ğŸŒ",
    title: "Research on Switzerland Global Competitiveness",
    location: "Columbia, South Carolina",
    dates: "Oct 2022",
    short: "Analyzed how culture impacts economic outcomes (also written before AI).",
    long: "Studied the roles of Hofstede and GLOBE cultural dimensions (e.g., power distance, individualism) on global competitiveness. Added regional insights by comparing corruption's effect on Northern vs. Southern Italy investments."
  },
  {
    emoji: "ğŸŒ",
    title: "Automated file converter (PowerShell)",
    location: "Columbia, South Carolina",
    dates: "Dec 2022",
    short: "Developed a script to convert hundreds of PowerPoint files into PDFs.",
    long: "Saved hours for my team and avoided an Adobe subscription by runnning an automation over all .ppt files in a folder."
  },
  {
    emoji: "ğŸ¥",
    title: "Data cleansing algorithm (Stata)",
    location: "Columbia, South Carolina",
    dates: "Apr 2022 â€“ Apr 2024",
    short: "Extracted thousands of messy files from Refinitiv then built script in Stata to clean and organize for Python ingestion",
    long: "I processed thousands of disparate datasets from archived Refinitiv data 1962-2023, creating a structured dataset with all investments by country and year, tagged with data such as round number, investment stage, and deal vallue."
  },
  {
    emoji: "ğŸ¥",
    title: "Global health investment algorithm (Excel Macros)",
    location: "Columbia, South Carolina",
    dates: "Apr 2022 â€“ Apr 2024",
    short: "Cleaned and structured massive datasets for global health investment trends.",
    long: "I wrote an Excel Macro to loop through thousands of files and compile data into a single large dataset. This was for the purpose of comparing Refinitiv data with enterprise investment data (including project team, project industry, type of product, etc). My work exposed which factors contributed most to a successful investment across the investor small teams."
  },
  {
    emoji: "ğŸ‘¾",
    title: "Bad actor algorithm (Python)",
    location: "Columbia, South Carolina",
    dates: "Jan 2021 â€“ May 2021",
    short: "Worked on a small team to create an anomaly detection algorithm that runs continuously based on user inputs.",
    long: "Improved the usability of the Army Big Data Platform using a backend based in the theory of k-means cardinality to detect abnormalities in daily data points collected in large quantities."
  },
  {
    emoji: "ğŸ§ª",
    title: "Disease detection algroithm (Python)",
    location: "West Point, New York",
    dates: "Aug â€“ Dec 2020",
    short: "Used machine learning to identify biological patterns in disease.",
    long: "Modeled biological markers using a multilabel transformation and support vector classifier. I achieved .02334 logistic loss."
  }
];

